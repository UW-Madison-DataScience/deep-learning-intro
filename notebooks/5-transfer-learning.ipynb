{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa205120",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92d5ad1",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "- How do I apply a pre-trained model to my data?\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- Adapt a state-of-the-art pre-trained network to your own dataset\n",
    "\n",
    "## What is transfer learning?\n",
    "Instead of training a model from scratch, with transfer learning you make use of models that are trained on another machine learning task. The pre-trained network captures generic knowledge during pre-training and will only be 'fine-tuned' to the specifics of your dataset.\n",
    "\n",
    "An example: Let's say that you want to train a model to classify images of different dog breeds. You could make use of a pre-trained network that learned how to classify images of dogs and cats. The pre-trained network will not know anything about different dog breeds, but it will have captured some general knowledge of, on a high-level, what dogs look like, and on a low-level all the different features (eyes, ears, paws, fur) that make up an image of a dog. Further training this model on your dog breed dataset is a much easier task than training from scratch, because the model can use the general knowledge captured in the pre-trained network.\n",
    "\n",
    "![](https://raw.githubusercontent.com/UW-Madison-DataScience/deep-learning-intro/main/images/05-transfer_learning.png)\n",
    "<!-- \n",
    "Edit this plot using the Mermaid live editor:\n",
    "1. Open this link that includes the source code of the chart to open the live editor web interface:\n",
    "https://mermaid.live/edit#pako:eNpVkE1vgzAMhv9K5MPUSrQKAWUlh0kr9NZetp02drAgUCRIqhC0dZT_vizso_PJb_zYr-MRCl1KEFC1-q04orFk_5Ar4uL-ZZHpuic3JEXbkwwtLl_JanVHLk8GG0UOrrO9kO3CJ-QKXs4T0tGBqq-kIXuJRjWqnubK1s9JZ5F5I7I1Upb_fL7rqRe7a8g7LiGATpoOm9J9YPyCc7BH2ckchEtLWeHQ2hxyNTkUB6sfz6oAYc0gAzB6qI8gKmx7p4ZTiVZmDdYGu9_XE6pnrf-0LBurzWE-mb-cZ0CM8A5iRdfUBeObmEZJzKOEJRHnUQBnECwK15zRMGJxzNkmoXwK4MMPD30bpSHjt5SHSfyzzs7bzQtPn9Xpf_E\n",
    "2. Make changes to the chart as desired in the live editor\n",
    "3. Download the newly created diagram from the live editor (Actions / PNG) and replace the existing image in the episode folder (episodes/fig/05-transfer_learning.png)\n",
    "4. (optional) crop the image to remove the white space around the plot in a separate image editor\n",
    "5. Update the URL in step 1 of this comment to the new URL of the live editor\n",
    "-->\n",
    "\n",
    "In this episode we will learn how use Keras to adapt a state-of-the-art pre-trained model to the [Dollar Street Dataset](https://zenodo.org/records/10970014).\n",
    "\n",
    "\n",
    "## 1. Formulate / Outline the problem\n",
    "\n",
    "\n",
    "Just like in the previous episode, we use the Dollar Street 10 dataset. \n",
    "\n",
    "We load the data in the same way as the previous episode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a163a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "DATA_FOLDER = pathlib.Path('data/') # change to location where you stored the data\n",
    "train_images = np.load(DATA_FOLDER / 'train_images.npy')\n",
    "val_images = np.load(DATA_FOLDER / 'test_images.npy')\n",
    "train_labels = np.load(DATA_FOLDER / 'train_labels.npy')\n",
    "val_labels = np.load(DATA_FOLDER / 'test_labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e7371d",
   "metadata": {},
   "source": [
    "## Callout: # Google Colab + GPUs recommended\n",
    "\n",
    "This episode uses a respectably sized neural network ‚Äî *DenseNet121*, which has 121 layers and over 7 million parameters. Training or \"finetuning\" this large of a model on a CPU is slow. Graphical Processing Units (GPUs) dramatically accelerate deep learning by speeding up the underlying matrix operations, often achieving **10-100x faster performance** than CPUs.\n",
    "\n",
    "To speed things up, we recommend using [Google Colab](https://colab.research.google.com/), which provides free access to a GPU. \n",
    "\n",
    "#### How to run this episode in Colab:\n",
    "\n",
    "A. **Upload the `dl_workshop` folder to your Google Drive.**  \n",
    "   This folder should contain the `data/` directory with the `.npy` files used in this episode. If the instructor has provided pre-filled notebooks for the workshop, please upload these as well.\n",
    "\n",
    "B. **Start a blank notebook in Colab or open pre-filled notebook provided by instructor**\n",
    "   Go to [https://colab.research.google.com/](https://colab.research.google.com/), click \"New Notebook\", and copy/paste code from this episode into cells.\n",
    "\n",
    "C. **Enable GPU:**\n",
    "   - Go to `Runtime > Change runtime type`\n",
    "   - Set \"Hardware accelerator\" to `GPU`\n",
    "   - Click \"Save\"\n",
    "\n",
    "D. **Mount your Google Drive in the notebook:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1f1dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d4fa08",
   "metadata": {},
   "source": [
    "E. **Set the data path to point to your uploaded folder, and load data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ced3623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "DATA_FOLDER = pathlib.Path('/content/drive/MyDrive/dl_workshop/data')\n",
    "train_images = np.load(DATA_FOLDER / 'train_images.npy')\n",
    "val_images = np.load(DATA_FOLDER / 'test_images.npy')\n",
    "train_labels = np.load(DATA_FOLDER / 'train_labels.npy')\n",
    "val_labels = np.load(DATA_FOLDER / 'test_labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dcc45f",
   "metadata": {},
   "source": [
    "F. **Check if GPU is active:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de239fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"GPU is available and will be used.\")\n",
    "else:\n",
    "    print(\"GPU not found. Training will use CPU and may be slow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cea614",
   "metadata": {},
   "source": [
    "Assuming you have installed the GPU-enabled version of TensorFlow (which is pre-installed in Colab), you don't need to do anything else to enable GPU usage during training, tuning, or inference. TensorFlow/Keras will automatically use the GPU whenever it's available and supported. Note ‚Äî we didn't include the GPU version of Tensorflow in this workshop's virtual environment because it can be finnicky to configure across operating systems, and many learners don't have the appropriate GPU hardware available.\n",
    "\n",
    "## 2. Identify inputs and outputs\n",
    "\n",
    "As discussed in the previous episode, the input are images of dimension 64 x 64 pixels with 3 colour channels each.\n",
    "The goal is to predict one out of 10 classes to which the image belongs.\n",
    "\n",
    "\n",
    "## 3. Prepare the data\n",
    "We prepare the data as before, scaling the values between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943caa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "val_images = val_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c41d51",
   "metadata": {},
   "source": [
    "## 4. Choose a pre-trained model or start building architecture from scratch\n",
    "Let's define our model input layer using the shape of our training images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88b619c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input tensor\n",
    "from tensorflow import keras\n",
    "inputs = keras.Input(train_images.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5c1cb",
   "metadata": {},
   "source": [
    "Our images are 64 x 64 pixels, whereas the pre-trained model that we will use was \n",
    "trained on images of 160 x 160 pixels.\n",
    "To adapt our data accordingly, we add an upscale layer that resizes the images to 160 x 160 pixels during training and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6802363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upscale layer\n",
    "import tensorflow as tf\n",
    "method = tf.image.ResizeMethod.BILINEAR\n",
    "upscale = keras.layers.Lambda(\n",
    "  lambda x: tf.image.resize_with_pad(x, 160, 160, method=method))(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbd3cf5",
   "metadata": {},
   "source": [
    "From the `keras.applications` module we use the `DenseNet121` architecture. \n",
    "This architecture was proposed by the paper: [Densely Connected Convolutional Networks (CVPR 2017)](https://arxiv.org/abs/1608.06993). It is trained on the [Imagenet](https://www.image-net.org/) dataset, which contains 14,197,122 annotated images according to the WordNet hierarchy with over 20,000 classes.\n",
    "\n",
    "We will have a look at the architecture later, for now it is enough to know\n",
    "that it is a convolutional neural network with 121 layers that was designed \n",
    "to work well on image classification tasks.\n",
    "\n",
    "Let's configure the DenseNet121:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c53b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.DenseNet121(include_top=False,\n",
    "                                            pooling='max',\n",
    "                                            weights='imagenet',\n",
    "                                            input_tensor=upscale,\n",
    "                                            input_shape=(160,160,3),\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9d1e63",
   "metadata": {},
   "source": [
    "## Callout: SSL: certificate verify failed error\n",
    "\n",
    "If you get the following error message: `certificate verify failed: unable to get local issuer certificate`,\n",
    "you can download [the weights of the model manually](https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5)\n",
    "and then load in the weights from the downloaded file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed13a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.DenseNet121(\n",
    "    include_top=False,\n",
    "    pooling='max',\n",
    "    weights='densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5', # this should refer to the weights file you downloaded\n",
    "    input_tensor=upscale,\n",
    "    input_shape=(160,160,3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ff32cf",
   "metadata": {},
   "source": [
    "By setting `include_top` to `False` we exclude the fully connected layer at the\n",
    "top of the network, hence the final output layer. This layer was used to predict the Imagenet classes,\n",
    "but will be of no use for our Dollar Street dataset.\n",
    "Note that the 'top layer' appears at the bottom in the output of `model.summary()`.\n",
    "\n",
    "We add `pooling='max'` so that max pooling is applied to the output of the DenseNet121 network.\n",
    "\n",
    "By setting `weights='imagenet'` we use the weights that resulted from training\n",
    "this network on the Imagenet data.\n",
    "\n",
    "We connect the network to the `upscale` layer that we defined before.\n",
    "\n",
    "### Only train a 'head' network\n",
    "Instead of fine-tuning all the weights of the DenseNet121 network using our dataset,\n",
    "we choose to freeze all these weights and only train a so-called 'head network' \n",
    "that sits on top of the pre-trained network. You can see the DenseNet121 network\n",
    "as extracting a meaningful feature representation from our image. The head network\n",
    "will then be trained to decide on which of the 10 Dollar Street dataset classes the image belongs.\n",
    "\n",
    "We will turn of the `trainable` property of the base model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440ab55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e4bcd4",
   "metadata": {},
   "source": [
    "Let's define our 'head' network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2330854",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = base_model.output\n",
    "out = keras.layers.Flatten()(out)\n",
    "out = keras.layers.BatchNormalization()(out)\n",
    "out = keras.layers.Dense(50, activation='relu')(out)\n",
    "out = keras.layers.Dropout(0.5)(out)\n",
    "out = keras.layers.Dense(10)(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ea0285",
   "metadata": {},
   "source": [
    "Finally we define our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d451746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Model(inputs=inputs, outputs=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b77b5b9",
   "metadata": {},
   "source": [
    "## Challenge: Inspect the DenseNet121 network\n",
    "\n",
    "Have a look at the network architecture with `model.summary()`.\n",
    "It is indeed a deep network, so expect a long summary!\n",
    "\n",
    "### 1.Trainable parameters\n",
    "How many parameters are there? How many of them are trainable? \n",
    "\n",
    "Why is this and how does it effect the time it takes to train the model?\n",
    "\n",
    "### 2. Head and base\n",
    "Can you see in the model summary which part is the base network and which part is the head network?\n",
    "\n",
    "### 3. Max pooling\n",
    "Which layer is added because we provided `pooling='max'` as argument for `DenseNet121()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2f02e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca49c99e",
   "metadata": {},
   "source": [
    "## Challenge: Training and evaluating the pre-trained model\n",
    "\n",
    "### 1. Compile the model\n",
    "Compile the model:\n",
    "\n",
    "- Use the `adam` optimizer \n",
    "- Use the `SparseCategoricalCrossentropy` loss with `from_logits=True`. \n",
    "- Use 'accuracy' as a metric.\n",
    "\n",
    "### 2. Train the model\n",
    "Train the model on the training dataset:\n",
    "\n",
    "- Use a batch size of 32\n",
    "- Train for 30 epochs, but use an earlystopper with a patience of 5\n",
    "- Pass the validation dataset as validation data so we can monitor performance on the validation data during training\n",
    "- Store the result of training in a variable called `history`\n",
    "- Training can take a while, it is a much larger model than what we have seen so far.\n",
    "\n",
    "### 3. Inspect the results\n",
    "Plot the training history and evaluate the trained model. What do you think of the results?\n",
    "\n",
    "### 4. (Optional) Try out other pre-trained neural networks\n",
    "Train and evaluate another pre-trained model from https://keras.io/api/applications/. How does it compare to DenseNet121?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c6b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Unfreeze top block of base model\n",
    "set_trainable = False\n",
    "for layer in base_model.layers:\n",
    "    if 'conv5' in layer.name:\n",
    "        set_trainable = True\n",
    "    layer.trainable = set_trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42830e95",
   "metadata": {},
   "source": [
    "### 2. Recompile the model\n",
    "Any time you change layer trainability, you **must recompile** the model.\n",
    "\n",
    "Use the same optimizer and loss function as before:\n",
    "- `optimizer='adam'`\n",
    "- `loss=SparseCategoricalCrossentropy(from_logits=True)`\n",
    "- `metrics=['accuracy']`\n",
    "\n",
    "### 3. Retrain the model\n",
    "Retrain the model using the same setup as before:\n",
    "\n",
    "- `batch_size=32`\n",
    "- `epochs=30`\n",
    "- Early stopping with `patience=5`\n",
    "- Pass in the validation set using `validation_data`\n",
    "- Store the result in a new variable called `history_finetune`\n",
    "\n",
    "> üìù You can reuse your `early_stopper` callback or redefine it.\n",
    "\n",
    "### 4. Compare with baseline (head only)\n",
    "Plot the **validation accuracy** for both the baseline and fine-tuned models.\n",
    "\n",
    "**Questions to reflect on:**\n",
    "- Did unfreezing part of the base model improve validation accuracy?\n",
    "- Did training time increase significantly?\n",
    "- Is there any evidence of overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd02858d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0447c3e0",
   "metadata": {},
   "source": [
    "## Concluding: The power of transfer learning\n",
    "In many domains, large networks are available that have been trained on vast amounts of data, such as in computer vision and natural language processing. Using transfer learning, you can benefit from the knowledge that was captured from another machine learning task. In many fields, transfer learning will outperform models trained from scratch, especially if your dataset is small or of poor quality.\n",
    "\n",
    "## Keypoints\n",
    "\n",
    "- Large pre-trained models capture generic knowledge about a domain\n",
    "- Use the `keras.applications` module to easily use pre-trained models for your own datasets"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
